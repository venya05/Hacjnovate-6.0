{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NnN5oqrS_lZt",
        "outputId": "1c8f64b0-f92e-4891-bbc4-674fce56a2bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.23.3-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.8.0 (from gradio)\n",
            "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.1)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.23.3-py3-none-any.whl (46.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.5/46.5 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.23.3 gradio-client-1.8.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.4 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.1 tomlkit-0.13.2 uvicorn-0.34.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbXMwFOCHZat",
        "outputId": "769c0eb1-fa03-4217-cde6-9f063efb362c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "OH6knR9s_NLP",
        "outputId": "49fd8374-ff46-4552-f50a-8ffa625e87f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-2e2190724375>:45: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(height=500, show_copy_button=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://7b6f7daaddd1915926.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://7b6f7daaddd1915926.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import base64\n",
        "\n",
        "# Function to encode images to base64\n",
        "def encode_image(image_path):\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        return f\"data:image/jpeg;base64,{base64.b64encode(image_file.read()).decode()}\"\n",
        "\n",
        "# Paths to local images\n",
        "image_path_home = \"/content/drive/MyDrive/home intro.jpg\"\n",
        "image_path_test = \"/content/drive/MyDrive/take_a_test.jpg\"\n",
        "image_path_therapy = \"/content/drive/MyDrive/online_therapy_img.jpg\"\n",
        "image_path_autism = \"/content/drive/MyDrive/ask_person_thinking.jpg\"\n",
        "image_path_contact = \"/content/drive/MyDrive/contact_us.jpg\"\n",
        "image_path_extra = \"/content/drive/MyDrive/test2.jpg\"\n",
        "\n",
        "# Convert images to base64\n",
        "image_home_base64 = encode_image(image_path_home)\n",
        "image_test_base64 = encode_image(image_path_test)\n",
        "image_therapy_base64 = encode_image(image_path_therapy)\n",
        "image_autism_base64 = encode_image(image_path_autism)\n",
        "image_contact_base64 = encode_image(image_path_contact)\n",
        "image_extra_base64 = encode_image(image_path_extra)\n",
        "\n",
        "def home():\n",
        "    return f\"\"\"<div style='background-color: #9FAC9D; padding: 20px; border-radius: 10px;'>\n",
        "                <div style='display: flex; align-items: center;'>\n",
        "                    <img src='{image_home_base64}' style='width: 40%; border-radius: 10px;'>\n",
        "                    <div style='padding-left: 20px;'>\n",
        "                        <h1 style='color: #2A363B; font-size: 48px;'>One Scan at a Time</h1>\n",
        "                        <p style='font-size: 20px;'>Autism Care is dedicated to early detection and support for individuals on the autism spectrum.\n",
        "                        Using MRI-based analysis and AI-driven insights, we provide accurate autism detection, personalized therapy,\n",
        "                        and medical report evaluation.</p>\n",
        "                    </div>\n",
        "                </div>\n",
        "            </div>\"\"\"\n",
        "\n",
        "def take_test():\n",
        "     return f\"\"\"\n",
        "    <div style=\"\n",
        "        background-image: url('file_path_placeholder.jpg');\n",
        "        background-size: cover;\n",
        "        background-position: center;\n",
        "        padding: 20px;\n",
        "        border-radius: 10px;\n",
        "    \">\n",
        "        <div style='background-color:#89999A; padding: 20px; border-radius: 10px;'>\n",
        "            <div style='display: flex; align-items: center;'>\n",
        "                <img src='{image_test_base64}' style='width: 40%; border-radius: 10px;'>\n",
        "                <div style='padding-left: 20px;'>\n",
        "                    <h2 style='font-size: 36px;'>Take a Test â€“ MRI-Based Autism Detection</h2>\n",
        "                    <p style='font-size: 20px;'>Upload your structural MRI scan and let our AI-powered system analyze it for autism detection.</p>\n",
        "                    <h3 style='font-size: 28px;'> How It Works?</h3>\n",
        "                    <ul style='font-size: 20px;'>\n",
        "                        <li>Upload your Structural MRI scan.</li>\n",
        "                        <li>Our AI processes the scan and analyzes key neurological markers.</li>\n",
        "                        <li>Receive a detailed report indicating the likelihood of autism.</li>\n",
        "                    </ul>\n",
        "                </div>\n",
        "            </div>\n",
        "            <div style='display: flex; align-items: center; margin-top: 20px;'>\n",
        "                <div style='flex: 1; padding-right: 20px;'>\n",
        "                    <h3 style='font-size: 28px;'> Additional Information</h3>\n",
        "                    <ul style='font-size: 20px;'>\n",
        "                        <li> Advanced AI-driven analytics.</li>\n",
        "                       <li> Bringing intelligence to healthcare in a new way.<li>\n",
        "                    </ul>\n",
        "                </div>\n",
        "                <img src='{image_extra_base64}' style='width: 40%; border-radius: 10px;'>\n",
        "            </div>\n",
        "        </div>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "\n",
        "def online_therapy():\n",
        "    return f\"\"\"\n",
        "    <div style='background-color: #ECE4D7; padding: 20px; border-radius: 10px;'>\n",
        "        <div style='display: flex; align-items: center;'>\n",
        "            <img src='{image_therapy_base64}' style='width: 40%; border-radius: 10px;'>\n",
        "            <div style='padding-left: 20px;'>\n",
        "                <h2 style='font-size: 36px;'>Online Therapy â€“ Support When You Need It</h2>\n",
        "                <p style='font-size: 20px;'>Living with autism comes with unique challenges. Our online therapy sessions are here to support you.</p>\n",
        "                <ul style='font-size: 20px;'>\n",
        "                    <li>ğŸŒ¿ One-on-one virtual sessions designed for your comfort</li>\n",
        "                    <li>ğŸ§© A safe, judgment-free space to express yourself</li>\n",
        "                </ul>\n",
        "            </div>\n",
        "        </div>\n",
        "        <iframe\n",
        "            src=\"https://agent.ai/agent/u3dd5r0epvfy3kdl\"\n",
        "            width=\"100%\"\n",
        "            height=\"600px\"\n",
        "            style=\"border:none; border-radius:10px; box-shadow:0 2px 8px rgba(0,0,0,0.1);\">\n",
        "        </iframe>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "\n",
        "def ask_about_autism():\n",
        "    return f\"\"\"<div style='background-color: #DDC8B7; padding: 20px; border-radius: 10px;'>\n",
        "                <div style='display: flex; align-items: center;'>\n",
        "                    <img src='{image_autism_base64}' style='width: 40%; border-radius: 10px;'>\n",
        "                    <div style='padding-left: 20px;'>\n",
        "                        <h2 style='font-size: 36px;'>Ask About Autism</h2>\n",
        "                        <p style='font-size: 20px;'>Have questions about autism? Weâ€™re here to help.</p>\n",
        "                        <ul style='font-size: 20px;'>\n",
        "                            <li>ğŸ§© Understand autism better</li>\n",
        "                            <li>ğŸ’™ Get insights</li>\n",
        "                            <li>ğŸ’¬ Ask without hesitation</li>\n",
        "                        </ul>\n",
        "                    </div>\n",
        "                </div>\n",
        "            </div>\"\"\"\n",
        "\n",
        "def contact_us():\n",
        "    return f\"\"\"<div style='background-color: #CDACA1; padding: 20px; border-radius: 10px;'>\n",
        "                <div style='display: flex; align-items: center;'>\n",
        "                    <img src='{image_contact_base64}' style='width: 40%; border-radius: 10px;'>\n",
        "                    <div style='padding-left: 20px;'>\n",
        "                        <h2 style='font-size: 36px;'>Contact Us</h2>\n",
        "                        <p style='font-size: 20px;'>Reach out to us for support and inquiries.</p>\n",
        "                        <p style='font-size: 20px;'>ğŸ“§ Email: autismcare@gmail.com</p>\n",
        "                        <p style='font-size: 20px;'>ğŸ“ Toll-Free: 1800-123-4567</p>\n",
        "                    </div>\n",
        "                </div>\n",
        "            </div>\"\"\"\n",
        "\n",
        "with gr.Blocks(css=\"\"\"\n",
        "    body { background-color: #89999A; color: #2A363B; font-family: Arial, sans-serif; }\n",
        "    .gradio-container { padding: 20px; }\n",
        "    h1 { font-size: 48px !important; }\n",
        "    h2 { font-size: 36px !important; }\n",
        "    h3 { font-size: 28px !important; }\n",
        "    p, li { font-size: 20px !important; }\n",
        "\"\"\") as demo:\n",
        "    gr.Markdown(\"\"\"<h1 style='text-align: left; color: #2A363B;'>Autism Care</h1>\"\"\")\n",
        "    with gr.Tabs():\n",
        "        with gr.Tab(\"Home\"):\n",
        "            gr.Markdown(home())\n",
        "            gr.Markdown(take_test())\n",
        "            gr.Markdown(online_therapy())\n",
        "            gr.Markdown(ask_about_autism())\n",
        "\n",
        "\n",
        "        with gr.Tab(\"Take a Test\"):\n",
        "            iface.render()\n",
        "\n",
        "        with gr.Tab(\"Online Therapy\"):\n",
        "            gr.Markdown(online_therapy())\n",
        "            therapy_planner()\n",
        "\n",
        "        with gr.Tab(\"Ask Anything About Autism\"):\n",
        "            ask_about_autism_chatbot()\n",
        "        with gr.Tab(\"Contact Us\"):\n",
        "            gr.Markdown(contact_us())\n",
        "\n",
        "demo.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "collapsed": true,
        "id": "QSzy7FeRVxAq",
        "outputId": "38310324-6fab-455f-dbdb-90d88c259c94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 8 variables whereas the saved optimizer has 14 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n",
            "/usr/local/lib/python3.11/dist-packages/gradio/interface.py:415: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://6482205204eab47d92.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6482205204eab47d92.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import tensorflow as tf\n",
        "import nibabel as nib\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Load the trained model\n",
        "model = tf.keras.models.load_model(\"/content/drive/MyDrive/autismdetct.keras\")\n",
        "\n",
        "def preprocess_image(nii_path, target_size=224):\n",
        "    \"\"\"Preprocess MRI image to match training pipeline\"\"\"\n",
        "    try:\n",
        "        # Load the .nii image\n",
        "        nii_img = nib.load(nii_path)\n",
        "        img_data = nii_img.get_fdata()\n",
        "\n",
        "        # Select a central slice\n",
        "        slice_2d = img_data[:, :, img_data.shape[2] // 2]\n",
        "\n",
        "        # Resize to target size\n",
        "        resized_slice = cv2.resize(slice_2d, (target_size, target_size))\n",
        "\n",
        "        # Normalize and apply Gaussian smoothing\n",
        "        normalized_slice = cv2.normalize(resized_slice, None, 0, 255, cv2.NORM_MINMAX)\n",
        "        blurred_slice = cv2.GaussianBlur(normalized_slice, (5, 5), 0)\n",
        "\n",
        "        # Reshape and add channel dimension\n",
        "        processed_image = blurred_slice.reshape(target_size, target_size, 1)\n",
        "\n",
        "        # Scale to [0,1] range\n",
        "        processed_image = processed_image.astype('float32') / 255.0\n",
        "\n",
        "        return processed_image\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Image processing failed: {str(e)}\")\n",
        "\n",
        "def extract_features(image):\n",
        "    \"\"\"Extract features using VGG16 architecture with correct output shape\"\"\"\n",
        "    # Initialize VGG16 model for feature extraction\n",
        "    vgg_base = tf.keras.applications.VGG16(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(224, 224, 3)\n",
        "    )\n",
        "\n",
        "    # Adapt for single-channel input by repeating the channel 3 times\n",
        "    if len(image.shape) == 3:\n",
        "        image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "\n",
        "    # Convert grayscale to \"RGB\" by repeating the channel\n",
        "    rgb_image = np.repeat(image, 3, axis=-1)\n",
        "\n",
        "    # Extract features (output shape will be (1, 7, 7, 512))\n",
        "    features = vgg_base.predict(rgb_image)\n",
        "    return features\n",
        "\n",
        "def predict_autism(uploaded_file_path):\n",
        "    try:\n",
        "        # Check file exists and is .nii\n",
        "        if not os.path.exists(uploaded_file_path):\n",
        "            return \"âŒ ERROR: File not found after upload.\"\n",
        "        if not uploaded_file_path.lower().endswith(\".nii\"):\n",
        "            return \"âŒ ERROR: Please upload a .nii file\"\n",
        "\n",
        "        # Process the image\n",
        "        processed_image = preprocess_image(uploaded_file_path)\n",
        "\n",
        "        # Extract features (shape will be (1, 7, 7, 512))\n",
        "        features = extract_features(processed_image)\n",
        "\n",
        "        # DON'T FLATTEN - your model expects (None, 7, 7, 512) shape\n",
        "        # Just pass the features directly\n",
        "        prediction = model.predict(features)\n",
        "        confidence = prediction[0][0]\n",
        "        result = \"Autistic\" if confidence > 0.5 else \"Not Autistic\"\n",
        "        return f\"âœ… Prediction: {result}\"\n",
        "\n",
        "    except nib.filebasedimages.ImageFileError:\n",
        "        return \"âŒ ERROR: Invalid NIfTI file. Please upload a valid .nii file.\"\n",
        "    except Exception as e:\n",
        "        return f\"âŒ ERROR: {str(e)}\"\n",
        "\n",
        "# Gradio Interface\n",
        "iface = gr.Interface(\n",
        "    fn=predict_autism,\n",
        "    inputs=gr.File(type=\"filepath\", label=\"Upload MRI Scan (.nii)\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"Autism Detection from MRI\",\n",
        "    description=\"Upload an MRI scan in .nii format to check for autism.\",\n",
        "    allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "iface.launch(debug=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VaRRY6GHsjcg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "4718d61e-d3be-42b8-a907-e5059636f1a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rerunning server... use `close()` to stop if you need to change `launch()` parameters.\n",
            "----\n",
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://7b6f7daaddd1915926.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://7b6f7daaddd1915926.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import openai\n",
        "import time\n",
        "from typing import List, Tuple\n",
        "\n",
        "# Configuration\n",
        "client = openai.OpenAI(\n",
        "    api_key=\"sk-DkstlbTPsZLDJtAV3862FA\",\n",
        "    base_url=\"https://chatapi.akash.network/api/v1\"\n",
        ")\n",
        "\n",
        "MODEL_NAME = \"Meta-Llama-3-1-8B-Instruct-FP8\"\n",
        "\n",
        "def query_akash_llm(prompt: str, history: List[Tuple[str, str]]) -> str:\n",
        "    \"\"\"Query Akash Network's LLM with proper message formatting\"\"\"\n",
        "    try:\n",
        "        messages = []\n",
        "        for user_msg, bot_msg in history:\n",
        "            messages.append({\"role\": \"user\", \"content\": user_msg})\n",
        "            if bot_msg:\n",
        "                messages.append({\"role\": \"assistant\", \"content\": bot_msg})\n",
        "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=MODEL_NAME,\n",
        "            messages=messages,\n",
        "            temperature=0.7,\n",
        "            max_tokens=500\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "def chat_interface(message, history):\n",
        "    \"\"\"Chat interface with input clearing\"\"\"\n",
        "    response = query_akash_llm(message, history)\n",
        "    history.append((message, response))\n",
        "\n",
        "    # Clear input after processing\n",
        "    yield history, \"\"\n",
        "\n",
        "def ask_about_autism_chatbot():\n",
        "    with gr.Column():\n",
        "        gr.Markdown(\"### ğŸ§  Autism & Mental Health Support\")\n",
        "        chatbot = gr.Chatbot(height=500, show_copy_button=True)\n",
        "        msg = gr.Textbox(\n",
        "            label=\"Your Question\",\n",
        "            placeholder=\"Ask about autism or mental health...\",\n",
        "            show_label=False\n",
        "        )\n",
        "\n",
        "        with gr.Row():\n",
        "            submit = gr.Button(\"Send\", variant=\"primary\")\n",
        "            clear = gr.Button(\"Clear\")\n",
        "\n",
        "        msg.submit(\n",
        "            chat_interface,\n",
        "            [msg, chatbot],\n",
        "            [chatbot, msg]\n",
        "        )\n",
        "\n",
        "        submit.click(\n",
        "            chat_interface,\n",
        "            [msg, chatbot],\n",
        "            [chatbot, msg]\n",
        "        )\n",
        "\n",
        "        clear.click(lambda: None, None, chatbot)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    demo.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nj0whoNvuAS"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Replace with your Agent.ai embed URL (looks like: https://agent.ai/widget/YOUR_AGENT_ID)\n",
        "AGENT_EMBED_URL = \"https://agent.ai/agent/u3dd5r0epvfy3kdl\"  # ğŸš¨ Get this from Agent.ai dashboard\n",
        "\n",
        "# ======== Create the Embedded UI ========\n",
        "with gr.Blocks(title=\"Autism Therapy Agent\", theme=gr.themes.Soft()) as app:\n",
        "    gr.Markdown(\"# ğŸŒˆ *Autism Therapy Helper*\")\n",
        "\n",
        "    # Embed Agent.ai iframe widget\n",
        "    gr.HTML(f\"\"\"\n",
        "    <iframe\n",
        "        src=\"{AGENT_EMBED_URL}\"\n",
        "        width=\"100%\"\n",
        "        height=\"600px\"\n",
        "        style=\"border:none; border-radius:10px; box-shadow:0 2px 8px rgba(0,0,0,0.1);\"\n",
        "    ></iframe>\n",
        "    \"\"\")\n",
        "\n",
        "# ======== Launch ========\n",
        "app.launch(share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "L5ddPJDoAngW"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "from openai import OpenAI\n",
        "\n",
        "# ======== AKASH NETWORK CONFIGURATION ========\n",
        "client = OpenAI(\n",
        "    api_key=\"sk-DkstlbTPsZLDJtAV3862FA\",\n",
        "    base_url=\"https://chatapi.akash.network/api/v1\"\n",
        ")\n",
        "\n",
        "MODEL_NAME = \"Meta-Llama-3-1-8B-Instruct-FP8\"\n",
        "\n",
        "# ======== THERAPY QUESTIONS ========\n",
        "QUESTIONS = [\n",
        "    \"Do loud noises often bother you?\",\n",
        "    \"Do you prefer strict daily routines?\",\n",
        "    \"Do you find eye contact uncomfortable?\",\n",
        "    \"Do you use gestures more than words to communicate?\",\n",
        "    \"Do unexpected changes cause anxiety?\",\n",
        "    \"Do you have specific sensory preferences (textures/tastes)?\",\n",
        "    \"Do social situations feel overwhelming?\",\n",
        "    \"Do you use repetitive movements for comfort?\",\n",
        "    \"Do you have intense focus on specific interests?\",\n",
        "    \"Do transitions between activities feel challenging?\",\n",
        "    \"Do you prefer written over verbal communication?\",\n",
        "    \"Do you notice patterns others might miss?\",\n",
        "    \"Do bright lights feel uncomfortable?\",\n",
        "    \"Do you need help with daily living skills?\",\n",
        "    \"Do you struggle with figurative language?\",\n",
        "    \"Do you have difficulty recognizing emotions in others?\",\n",
        "    \"Do you use special items for self-soothing?\",\n",
        "    \"Do group settings feel more challenging than 1:1?\",\n",
        "    \"Do you experience meltdowns when overwhelmed?\",\n",
        "    \"Would visual schedules help with daily tasks?\"\n",
        "]\n",
        "\n",
        "# ======== CORE FUNCTIONALITY ========\n",
        "def generate_therapy_plan(answers):\n",
        "    \"\"\"Generate personalized therapy plan using Akash Network's LLM\"\"\"\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=MODEL_NAME,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": f\"\"\"\n",
        "                Create a personalized autism therapy plan based on these answers:\n",
        "                {answers}\n",
        "\n",
        "                Include:\n",
        "                1. Recommended therapies (ABA, OT, etc.)\n",
        "                2. Daily activity suggestions\n",
        "                3. Sensory tools/adaptations\n",
        "                4. Social skills strategies\n",
        "                5. Emotional regulation techniques\n",
        "                \"\"\"},\n",
        "                {\"role\": \"user\", \"content\": \"Format the plan with clear headings and bullet points\"}\n",
        "            ],\n",
        "            temperature=0.7,\n",
        "            max_tokens=500\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"âš ï¸ Error generating plan: {str(e)}\"\n",
        "\n",
        "# ======== GRADIO UI ========\n",
        "def therapy_planner():\n",
        "  with gr.Blocks(theme=gr.themes.Soft()) as app:\n",
        "    current_question = gr.State(0)\n",
        "    user_answers = gr.State([])\n",
        "\n",
        "    with gr.Column():\n",
        "        gr.Markdown(\"# ğŸŒˆ *Autism Therapy Planner*\")\n",
        "        progress = gr.Slider(1, 20, step=1, label=\"Progress\")\n",
        "        question_box = gr.Markdown()\n",
        "\n",
        "        with gr.Row():\n",
        "            yes_btn = gr.Button(\"Yes âœ…\", variant=\"primary\")\n",
        "            no_btn = gr.Button(\"No âŒ\", variant=\"secondary\")\n",
        "\n",
        "        result = gr.Markdown(visible=False)\n",
        "        restart_btn = gr.Button(\"Restart Assessment ğŸ”„\", visible=False)\n",
        "\n",
        "    # ======== INTERACTION HANDLERS ========\n",
        "    def handle_answer(answer):\n",
        "        def update_state(question, answers):\n",
        "            new_answers = answers + [answer]\n",
        "            next_q = question + 1\n",
        "\n",
        "            if next_q < len(QUESTIONS):\n",
        "                return {\n",
        "                    question_box: f\"*{QUESTIONS[next_q]}*\",\n",
        "                    current_question: next_q,\n",
        "                    user_answers: new_answers,\n",
        "                    progress: next_q,\n",
        "                    result: gr.update(visible=False)\n",
        "                }\n",
        "            else:\n",
        "                plan = generate_therapy_plan(new_answers)\n",
        "                return {\n",
        "                    question_box: \"*Assessment Complete!*\",\n",
        "                    current_question: 0,\n",
        "                    user_answers: [],\n",
        "                    progress: 20,\n",
        "                    result: gr.Markdown(f\"## ğŸ§  Personalized Plan\\n\\n{plan}\", visible=True),\n",
        "                    restart_btn: gr.update(visible=True)\n",
        "                }\n",
        "        return update_state\n",
        "\n",
        "    yes_btn.click(\n",
        "        handle_answer(\"Yes\"),\n",
        "        [current_question, user_answers],\n",
        "        [question_box, current_question, user_answers, progress, result, restart_btn]\n",
        "    )\n",
        "\n",
        "    no_btn.click(\n",
        "        handle_answer(\"No\"),\n",
        "        [current_question, user_answers],\n",
        "        [question_box, current_question, user_answers, progress, result, restart_btn]\n",
        "    )\n",
        "\n",
        "    def restart():\n",
        "        return {\n",
        "            question_box: f\"*{QUESTIONS[0]}*\",\n",
        "            current_question: 0,\n",
        "            user_answers: [],\n",
        "            progress: 0,\n",
        "            result: gr.update(visible=False),\n",
        "            restart_btn: gr.update(visible=False)\n",
        "        }\n",
        "\n",
        "    restart_btn.click(restart, outputs=[\n",
        "        question_box, current_question, user_answers,\n",
        "        progress, result, restart_btn\n",
        "    ])\n",
        "\n",
        "    app.load(lambda: {question_box: f\"*{QUESTIONS[0]}*\"}, outputs=[question_box])\n",
        "    return app\n",
        "    app.launch(share=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3YasBLy8F3jYdoInzO3br"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}